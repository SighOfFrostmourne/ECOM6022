{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vLaTEpG3cT1"
      },
      "source": [
        "**Topic 3 – Classification**\n",
        "\n",
        "This notebook contains all the sample code provided by the author of our textbook for Topic 3 - Classification, with some additional comments and explanations.  Your reading assignment is Chapter 3 of the textbook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAG6JXF13cUB"
      },
      "source": [
        "# Setup\n",
        "As in all Colab notebooks, let us import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2eIX7lh3cUC"
      },
      "outputs": [],
      "source": [
        "# Common imports, generally used througout this course\n",
        "import numpy as np\n",
        "import os\n",
        "import sklearn\n",
        "\n",
        "# to make this notebook's output stable across runs (ensure repeatibility)\n",
        "np.random.seed(42)   # we shall use seed(42) throughout\n",
        "\n",
        "# To plot pretty figures (we have also used this in previous topics)\n",
        "%matplotlib inline  \n",
        "# function to activate interactive support for matplotlib\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures (the default here is /content/images/Classification)\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"classification\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oILbLRyR3cUD"
      },
      "source": [
        "# MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCgObU0u3cUE"
      },
      "source": [
        "**Warning (provided by the textbook author for compatibility):** since Scikit-Learn 0.24, `fetch_openml()` returns a Pandas `DataFrame` by default. To avoid this and keep the same code as in the book, we use `as_frame=False`.  That is, this codebook could have used Panda DataFrame instead, but "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFnRXENt3cUE"
      },
      "outputs": [],
      "source": [
        "# Import MNIST handwritten digits dataset from \"openml\" available in Scikit-Learn\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "mnist.keys()   # have a look at the keys of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lOThbZu3cUF"
      },
      "outputs": [],
      "source": [
        "# Remember - the shape and structure of the dataset are more important than the values!\n",
        "# Both X and y are Numpy ndarrays\n",
        "X, y = mnist[\"data\"], mnist[\"target\"]\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD2WK2Am3cUG"
      },
      "outputs": [],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NwfnVph3cUH"
      },
      "outputs": [],
      "source": [
        "# The digit imsages are 28 x 28 pixels = 784 (hence name of the dataset!)\n",
        "28 * 28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzyvaWDy3cUH"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "some_digit = X[0]   # have a look at the first digit image of dataset\n",
        "# need to reshape 1D ndarray to a 2D ndarray for display\n",
        "some_digit_image = some_digit.reshape(28, 28)\n",
        "plt.imshow(some_digit_image, cmap=mpl.cm.binary)\n",
        "plt.axis(\"off\")\n",
        "\n",
        "save_fig(\"some_digit_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71bBbZ_R3cUI"
      },
      "outputs": [],
      "source": [
        "y[0]  # note that the target label is a string!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hc1q4aK-3cUI"
      },
      "outputs": [],
      "source": [
        "y = y.astype(np.uint8) # recast the target 'y' to 8-bit integers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "ZeRdqprEeQkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNS56VRf3cUI"
      },
      "outputs": [],
      "source": [
        "def plot_digit(data):\n",
        "    image = data.reshape(28, 28)\n",
        "    plt.imshow(image, cmap = mpl.cm.binary,\n",
        "               interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uFCPJ9W3cUJ"
      },
      "outputs": [],
      "source": [
        "# Function to plot the first 100 digit images to get some idea of the dataset\n",
        "def plot_digits(instances, images_per_row=10, **options):\n",
        "    size = 28\n",
        "    images_per_row = min(len(instances), images_per_row)\n",
        "    # This is equivalent to n_rows = ceil(len(instances) / images_per_row):\n",
        "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
        "\n",
        "    # Append empty images to fill the end of the grid, if needed:\n",
        "    n_empty = n_rows * images_per_row - len(instances)\n",
        "    padded_instances = np.concatenate([instances, np.zeros((n_empty, size * size))], axis=0)\n",
        "\n",
        "    # Reshape the array so it's organized as a grid containing 28×28 images:\n",
        "    image_grid = padded_instances.reshape((n_rows, images_per_row, size, size))\n",
        "\n",
        "    # Combine axes 0 and 2 (vertical image grid axis, and vertical image axis),\n",
        "    # and axes 1 and 3 (horizontal axes). We first need to move the axes that we\n",
        "    # want to combine next to each other, using transpose(), and only then we\n",
        "    # can reshape:\n",
        "    big_image = image_grid.transpose(0, 2, 1, 3).reshape(n_rows * size,\n",
        "                                                         images_per_row * size)\n",
        "    # Now that we have a big image, we just need to show it:\n",
        "    plt.imshow(big_image, cmap = mpl.cm.binary, **options)\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEJblFcw3cUJ"
      },
      "outputs": [],
      "source": [
        "# plot image in a 10 x 10 grid\n",
        "plt.figure(figsize=(9,9))\n",
        "example_images = X[:100]\n",
        "plot_digits(example_images, images_per_row=10)\n",
        "save_fig(\"more_digits_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kETq7Eo3cUK"
      },
      "outputs": [],
      "source": [
        "y[0] # first digit is a '5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxQKUEFh3cUK"
      },
      "outputs": [],
      "source": [
        "# MNIST dataset is already divided into stratified and randomized data\n",
        "# first 60,000 digits is training set and the rest (40,000) are testing set\n",
        "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOo36oUn3cUK"
      },
      "source": [
        "# Training a Binary Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9c-6J2Y3cUK"
      },
      "outputs": [],
      "source": [
        "# let us extract all the '5' digit images for a 5-detector (both train and test datasets)\n",
        "y_train_5 = (y_train == 5)\n",
        "y_test_5 = (y_test == 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LaTuzbC3cUL"
      },
      "source": [
        "**Note**: some hyperparameters will have a different defaut value in future versions of Scikit-Learn, such as `max_iter` and `tol`. To be future-proof, we explicitly set these hyperparameters to their future default values. For simplicity, this is not shown in the book."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldFJYwkE3cUL"
      },
      "outputs": [],
      "source": [
        "# First, experiment with a simple Stochastic Gradient Descent Classifier\n",
        "# Note how easy it is to train the classifier and the use of .fit() method\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
        "sgd_clf.fit(X_train, y_train_5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bih2rnY03cUL"
      },
      "outputs": [],
      "source": [
        "# Then use the model to predict the class, which is a '5'\n",
        "sgd_clf.predict([some_digit])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AoHHwC83cUL"
      },
      "outputs": [],
      "source": [
        "# We can use cross-validation and then get score for each 'fold' (we have 3 folds)\n",
        "from sklearn.model_selection import cross_val_score\n",
        "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB2D9Kaw3cUL"
      },
      "source": [
        "# Performance Measures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU35xw763cUM"
      },
      "source": [
        "## Measuring Accuracy Using Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giiLH1wD3cUM"
      },
      "outputs": [],
      "source": [
        "# This is a side box in the textbook. As the dataset is already stratified, \n",
        "# we do not need to stratified it.  This section shows how you can do the\n",
        "# stratification youself.  It will give a slightly different score for each \n",
        "# fold as the stratified datasets would be different.\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.base import clone\n",
        "\n",
        "skfolds = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
        "    clone_clf = clone(sgd_clf)\n",
        "    X_train_folds = X_train[train_index]\n",
        "    y_train_folds = y_train_5[train_index]\n",
        "    X_test_fold = X_train[test_index]\n",
        "    y_test_fold = y_train_5[test_index]\n",
        "\n",
        "    clone_clf.fit(X_train_folds, y_train_folds)\n",
        "    y_pred = clone_clf.predict(X_test_fold)\n",
        "    n_correct = sum(y_pred == y_test_fold)\n",
        "    print(n_correct / len(y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79h0AWtK3cUM"
      },
      "source": [
        "**Note**: `shuffle=True` was omitted by mistake in previous releases of the book."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2GvTHUe3cUM"
      },
      "outputs": [],
      "source": [
        "# This is a dummy Classifier, which NEVER classify any input as '5'\n",
        "from sklearn.base import BaseEstimator\n",
        "class Never5Classifier(BaseEstimator):\n",
        "    def fit(self, X, y=None):\n",
        "        pass\n",
        "    def predict(self, X):\n",
        "        return np.zeros((len(X), 1), dtype=bool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mv7Vg3BY3cUM"
      },
      "outputs": [],
      "source": [
        "# This is to demonstrate the accuracy score is a bad performance measure!\n",
        "never_5_clf = Never5Classifier()\n",
        "cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.zeros((5, 1), dtype=bool))"
      ],
      "metadata": {
        "id": "EKxE6bd7nfx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Oilg31g3cUN"
      },
      "source": [
        "**Warning (by the textbook author)**: this output (and many others in this notebook and other notebooks) may differ slightly from those in the book. Don't worry, that's okay! There are several reasons for this:\n",
        "* first, Scikit-Learn and other libraries evolve, and algorithms get tweaked a bit, which may change the exact result you get. If you use the latest Scikit-Learn version (and in general, you really should), you probably won't be using the exact same version I used when I wrote the book or this notebook, hence the difference. I try to keep this notebook reasonably up to date, but I can't change the numbers on the pages in your copy of the book.\n",
        "* second, many training algorithms are stochastic, meaning they rely on randomness. In principle, it's possible to get consistent outputs from a random number generator by setting the seed from which it generates the pseudo-random numbers (which is why you will see `random_state=42` or `np.random.seed(42)` pretty often). However, sometimes this does not suffice due to the other factors listed here.\n",
        "* third, if the training algorithm runs across multiple threads (as do some algorithms implemented in C) or across multiple processes (e.g., when using the `n_jobs` argument), then the precise order in which operations will run is not always guaranteed, and thus the exact result may vary slightly.\n",
        "* lastly, other things may prevent perfect reproducibility, such as Python dicts and sets whose order is not guaranteed to be stable across sessions, or the order of files in a directory which is also not guaranteed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xbgj7Nms3cUN"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VrdSyQ93cUN"
      },
      "outputs": [],
      "source": [
        "# as prediction accuracy is not a good measure, we introduce Confusion Matrix\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6zxUGJi3cUN"
      },
      "outputs": [],
      "source": [
        "# compute the confusion matrix from the predictions\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(y_train_5, y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhEhHtp53cUN"
      },
      "outputs": [],
      "source": [
        "# pretend we have perfect prediction\n",
        "y_train_perfect_predictions = y_train_5\n",
        "confusion_matrix(y_train_5, y_train_perfect_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OhTMCF63cUO"
      },
      "source": [
        "## Precision and Recall\n",
        "\n",
        "Let us look at \"Precision\" (or \"accuracy\") and \"Recall\" (or \"sensitivity\") using `precision_score` and `recall_score`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCzKofAu3cUO"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "precision_score(y_train_5, y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXUhoxsl3cUO"
      },
      "outputs": [],
      "source": [
        "# It is easy to compute the precision and recall from the confusion matrix\n",
        "cm = confusion_matrix(y_train_5, y_train_pred)\n",
        "cm[1, 1] / (cm[0, 1] + cm[1, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ag_cRvbl3cUO"
      },
      "outputs": [],
      "source": [
        "recall_score(y_train_5, y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4t4jLhSB3cUO"
      },
      "outputs": [],
      "source": [
        "cm[1, 1] / (cm[1, 0] + cm[1, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RR7-gPzW3cUO"
      },
      "outputs": [],
      "source": [
        "# We have NOT discuss F! score in our lecture, which is the harmonic mean of precision and recall\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(y_train_5, y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdpeNhXK3cUP"
      },
      "outputs": [],
      "source": [
        "cm[1, 1] / (cm[1, 1] + (cm[1, 0] + cm[0, 1]) / 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn0EJobT3cUP"
      },
      "source": [
        "## Precision/Recall Trade-off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-S3jzPh3cUP"
      },
      "outputs": [],
      "source": [
        "# Codes to demonstrate the trade-off between precision and recall\n",
        "# the classifier computes a a 'decison_function' value as a score for classification\n",
        "# you can get this score\n",
        "y_scores = sgd_clf.decision_function([some_digit])\n",
        "y_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDDdLtz43cUP"
      },
      "outputs": [],
      "source": [
        "# you set the threshold (default is '0') to make the final prediction\n",
        "threshold = 0\n",
        "y_some_digit_pred = (y_scores > threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKd5G9Os3cUP"
      },
      "outputs": [],
      "source": [
        "y_some_digit_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnMJLAUK3cUP"
      },
      "outputs": [],
      "source": [
        "# raising the thresold will make a wrong prediction (score was '2164')\n",
        "threshold = 8000\n",
        "y_some_digit_pred = (y_scores > threshold)\n",
        "y_some_digit_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pk-aFSU23cUP"
      },
      "outputs": [],
      "source": [
        "# Now classify using cross-validatikon with 3 folds, using 'decision_function'\n",
        "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3,\n",
        "                             method=\"decision_function\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHwWAxBG3cUQ"
      },
      "outputs": [],
      "source": [
        "# Extract the precisions, recalls and thresholds data from precision_recall_curve()\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LuJJeK63cUQ"
      },
      "outputs": [],
      "source": [
        "# plot to show the trade-off between precision and recall\n",
        "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
        "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)\n",
        "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
        "    plt.legend(loc=\"center right\", fontsize=16) # Not shown in the book\n",
        "    plt.xlabel(\"Threshold\", fontsize=16)        # Not shown\n",
        "    plt.grid(True)                              # Not shown\n",
        "    plt.axis([-50000, 50000, 0, 1])             # Not shown\n",
        "\n",
        "\n",
        "\n",
        "recall_90_precision = recalls[np.argmax(precisions >= 0.90)]\n",
        "threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)]\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 4))                                                                  # Not shown\n",
        "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
        "plt.plot([threshold_90_precision, threshold_90_precision], [0., 0.9], \"r:\")                 # Not shown\n",
        "plt.plot([-50000, threshold_90_precision], [0.9, 0.9], \"r:\")                                # Not shown\n",
        "plt.plot([-50000, threshold_90_precision], [recall_90_precision, recall_90_precision], \"r:\")# Not shown\n",
        "plt.plot([threshold_90_precision], [0.9], \"ro\")                                             # Not shown\n",
        "plt.plot([threshold_90_precision], [recall_90_precision], \"ro\")                             # Not shown\n",
        "save_fig(\"precision_recall_vs_threshold_plot\")                                              # Not shown\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbnfCGuJ3cUQ"
      },
      "outputs": [],
      "source": [
        "(y_train_pred == (y_scores > 0)).all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_PqCsMY3cUQ"
      },
      "outputs": [],
      "source": [
        "# Plot precision vs recall for our model\n",
        "def plot_precision_vs_recall(precisions, recalls):\n",
        "    plt.plot(recalls, precisions, \"b-\", linewidth=2)\n",
        "    plt.xlabel(\"Recall\", fontsize=16)\n",
        "    plt.ylabel(\"Precision\", fontsize=16)\n",
        "    plt.axis([0, 1, 0, 1])\n",
        "    plt.grid(True)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plot_precision_vs_recall(precisions, recalls)\n",
        "plt.plot([recall_90_precision, recall_90_precision], [0., 0.9], \"r:\")\n",
        "plt.plot([0.0, recall_90_precision], [0.9, 0.9], \"r:\")\n",
        "plt.plot([recall_90_precision], [0.9], \"ro\")\n",
        "save_fig(\"precision_vs_recall_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7jtrw1n3cUQ"
      },
      "outputs": [],
      "source": [
        "threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwXvhDqt3cUQ"
      },
      "outputs": [],
      "source": [
        "threshold_90_precision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gf0JTuHL3cUR"
      },
      "outputs": [],
      "source": [
        "y_train_pred_90 = (y_scores >= threshold_90_precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2vzZ-Sf3cUR"
      },
      "outputs": [],
      "source": [
        "precision_score(y_train_5, y_train_pred_90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecRoc4Bx3cUR"
      },
      "outputs": [],
      "source": [
        "recall_score(y_train_5, y_train_pred_90)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VDp9DKu3cUR"
      },
      "source": [
        "## The ROC Curve (*Receiver Operation Characteristic Curve*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_TPovY23cUR"
      },
      "outputs": [],
      "source": [
        "# Another performance measurement is the ROC curve ()\n",
        "# Which is a plot of True Positive Rate (tpr) vs False Positive Rate (fpr)\n",
        "# Note the order of the return data from the roc_curve() function\n",
        "# FPR, TPR then THRESHOLDS in that order\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzVhJKJ83cUR"
      },
      "outputs": [],
      "source": [
        "def plot_roc_curve(fpr, tpr, label=None):\n",
        "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
        "    plt.plot([0, 1], [0, 1], 'k--') # dashed diagonal\n",
        "    plt.axis([0, 1, 0, 1])                                    # Not shown in the book\n",
        "    plt.xlabel('False Positive Rate (Fall-Out)', fontsize=16) # Not shown\n",
        "    plt.ylabel('True Positive Rate (Recall)', fontsize=16)    # Not shown\n",
        "    plt.grid(True)                                            # Not shown\n",
        "\n",
        "plt.figure(figsize=(8, 6))                                    # Not shown\n",
        "plot_roc_curve(fpr, tpr)\n",
        "fpr_90 = fpr[np.argmax(tpr >= recall_90_precision)]           # Not shown\n",
        "plt.plot([fpr_90, fpr_90], [0., recall_90_precision], \"r:\")   # Not shown\n",
        "plt.plot([0.0, fpr_90], [recall_90_precision, recall_90_precision], \"r:\")  # Not shown\n",
        "plt.plot([fpr_90], [recall_90_precision], \"ro\")               # Not shown\n",
        "save_fig(\"roc_curve_plot\")                                    # Not shown\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5T0EXrmv3cUS"
      },
      "outputs": [],
      "source": [
        "# Area Under Curve (AUC) is used to evaluate the ROC curve\n",
        "# For random data AUC = 0.5, for perfect classification AUC = 1.0\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "roc_auc_score(y_train_5, y_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Il-fsoV63cUS"
      },
      "source": [
        "**Note**: we set `n_estimators=100` to be future-proof since this will be the default value in Scikit-Learn 0.22."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcT6__gO3cUS"
      },
      "outputs": [],
      "source": [
        "# Try a new classifier - Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3,\n",
        "                                    method=\"predict_proba\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ls6iV6BT3cUS"
      },
      "outputs": [],
      "source": [
        "y_scores_forest = y_probas_forest[:, 1] # score = proba of positive class\n",
        "fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5,y_scores_forest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shTp3URQ3cUS"
      },
      "outputs": [],
      "source": [
        "recall_for_forest = tpr_forest[np.argmax(fpr_forest >= fpr_90)]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, \"b:\", linewidth=2, label=\"SGD\")\n",
        "plot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\n",
        "plt.plot([fpr_90, fpr_90], [0., recall_90_precision], \"r:\")\n",
        "plt.plot([0.0, fpr_90], [recall_90_precision, recall_90_precision], \"r:\")\n",
        "plt.plot([fpr_90], [recall_90_precision], \"ro\")\n",
        "plt.plot([fpr_90, fpr_90], [0., recall_for_forest], \"r:\")\n",
        "plt.plot([fpr_90], [recall_for_forest], \"ro\")\n",
        "plt.grid(True)\n",
        "plt.legend(loc=\"lower right\", fontsize=16)\n",
        "save_fig(\"roc_curve_comparison_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bV71I4T3cUS"
      },
      "outputs": [],
      "source": [
        "roc_auc_score(y_train_5, y_scores_forest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xy-OzpW33cUS"
      },
      "outputs": [],
      "source": [
        "y_train_pred_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3)\n",
        "precision_score(y_train_5, y_train_pred_forest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3NoUICH3cUT"
      },
      "outputs": [],
      "source": [
        "recall_score(y_train_5, y_train_pred_forest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9t0afTU3cUT"
      },
      "source": [
        "# Multiclass Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1hMfOtX3cUT"
      },
      "outputs": [],
      "source": [
        "# Demonstrate multiclass classification using Support Vector Classifier (SVC)\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_clf = SVC(gamma=\"auto\", random_state=42)\n",
        "svm_clf.fit(X_train[:1000], y_train[:1000]) # y_train, not y_train_5\n",
        "svm_clf.predict([some_digit])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5F-q4PD3cUT"
      },
      "outputs": [],
      "source": [
        "some_digit_scores = svm_clf.decision_function([some_digit])\n",
        "some_digit_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSWrGBqT3cUT"
      },
      "outputs": [],
      "source": [
        "np.argmax(some_digit_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxPqpbRa3cUT"
      },
      "outputs": [],
      "source": [
        "svm_clf.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lv3bzbsw3cUT"
      },
      "outputs": [],
      "source": [
        "svm_clf.classes_[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYUAI_s43cUU"
      },
      "outputs": [],
      "source": [
        "# Example of One-Versus-Rest Strategy using Support Vector Classifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "ovr_clf = OneVsRestClassifier(SVC(gamma=\"auto\", random_state=42))\n",
        "ovr_clf.fit(X_train[:1000], y_train[:1000])\n",
        "ovr_clf.predict([some_digit])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kr087cIh3cUU"
      },
      "outputs": [],
      "source": [
        "len(ovr_clf.estimators_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huh0yYIS3cUU"
      },
      "outputs": [],
      "source": [
        "sgd_clf.fit(X_train, y_train)\n",
        "sgd_clf.predict([some_digit])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbqMVmRg3cUU"
      },
      "outputs": [],
      "source": [
        "sgd_clf.decision_function([some_digit])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PciXIFlt3cUU"
      },
      "source": [
        "**Warning**: the following two cells may take close to 30 minutes to run, or more depending on your hardware."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXkL4V9D3cUU"
      },
      "outputs": [],
      "source": [
        "# Try SGD Classifier but with Cross-Validation on the entire training set\n",
        "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YA_cVni3cUU"
      },
      "outputs": [],
      "source": [
        "# Adding attribute scaling (suing StandardScaler) will improve performance\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
        "cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQjH314x3cUV"
      },
      "source": [
        "# Error Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7BawFjp3cUV"
      },
      "outputs": [],
      "source": [
        "# Let us analyse the error by a deep dive on the confusion matrix\n",
        "y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
        "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
        "conf_mx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcdDc5rv3cUV"
      },
      "outputs": [],
      "source": [
        "# since sklearn 0.22, you can use sklearn.metrics.plot_confusion_matrix()\n",
        "def plot_confusion_matrix(matrix):\n",
        "    \"\"\"If you prefer color and a colorbar\"\"\"\n",
        "    fig = plt.figure(figsize=(8,8))\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(matrix)\n",
        "    fig.colorbar(cax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxXDp_-D3cUV"
      },
      "outputs": [],
      "source": [
        "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
        "save_fig(\"confusion_matrix_plot\", tight_layout=False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeSK0S453cUV"
      },
      "outputs": [],
      "source": [
        "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
        "norm_conf_mx = conf_mx / row_sums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bR37v7Dq3cUV"
      },
      "outputs": [],
      "source": [
        "np.fill_diagonal(norm_conf_mx, 0)\n",
        "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
        "save_fig(\"confusion_matrix_errors_plot\", tight_layout=False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C97B4-fr3cUV"
      },
      "outputs": [],
      "source": [
        "# A closer look at correct and incorrect classifications for '3' and '5'\n",
        "cl_a, cl_b = 3, 5\n",
        "X_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)]\n",
        "X_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]\n",
        "X_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]\n",
        "X_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.subplot(221); plot_digits(X_aa[:25], images_per_row=5)\n",
        "plt.subplot(222); plot_digits(X_ab[:25], images_per_row=5)\n",
        "plt.subplot(223); plot_digits(X_ba[:25], images_per_row=5)\n",
        "plt.subplot(224); plot_digits(X_bb[:25], images_per_row=5)\n",
        "save_fig(\"error_analysis_digits_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7xPytXi3cUW"
      },
      "source": [
        "# Multilabel Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZ6CwDCL3cUW"
      },
      "outputs": [],
      "source": [
        "# Demonstraton of Multilabel Classification\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "y_train_large = (y_train >= 7)\n",
        "y_train_odd = (y_train % 2 == 1)\n",
        "y_multilabel = np.c_[y_train_large, y_train_odd]\n",
        "\n",
        "knn_clf = KNeighborsClassifier()\n",
        "knn_clf.fit(X_train, y_multilabel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rMag7qt3cUW"
      },
      "outputs": [],
      "source": [
        "knn_clf.predict([some_digit])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP6Yg1ko3cUW"
      },
      "source": [
        "**Warning**: the following cell may take a very long time (possibly hours depending on your hardware)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iktjXkku3cUW"
      },
      "outputs": [],
      "source": [
        "# Demonstrate Cross-Validation using KNN classifier (take long time to complete)\n",
        "y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)\n",
        "f1_score(y_multilabel, y_train_knn_pred, average=\"macro\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G3NoX2B3cUW"
      },
      "source": [
        "# Multioutput Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94_FvwsL3cUW"
      },
      "outputs": [],
      "source": [
        "# Demonstrate multioutput - multilabel classifier\n",
        "noise = np.random.randint(0, 100, (len(X_train), 784))\n",
        "X_train_mod = X_train + noise\n",
        "noise = np.random.randint(0, 100, (len(X_test), 784))\n",
        "X_test_mod = X_test + noise\n",
        "y_train_mod = X_train\n",
        "y_test_mod = X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4NQJbQE3cUW"
      },
      "outputs": [],
      "source": [
        "some_index = 0\n",
        "plt.subplot(121); plot_digit(X_test_mod[some_index])\n",
        "plt.subplot(122); plot_digit(y_test_mod[some_index])\n",
        "save_fig(\"noisy_digit_example_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyzW1bhq3cUX"
      },
      "outputs": [],
      "source": [
        "knn_clf.fit(X_train_mod, y_train_mod)\n",
        "clean_digit = knn_clf.predict([X_test_mod[some_index]])\n",
        "plot_digit(clean_digit)\n",
        "save_fig(\"cleaned_digit_example_plot\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "03_classification.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}